{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2445,"sourceType":"datasetVersion","datasetId":1355}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-15T15:25:52.918106Z","iopub.execute_input":"2024-10-15T15:25:52.918590Z","iopub.status.idle":"2024-10-15T15:25:52.950355Z","shell.execute_reply.started":"2024-10-15T15:25:52.918547Z","shell.execute_reply":"2024-10-15T15:25:52.948972Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"/kaggle/input/titanic/train_data.csv\n/kaggle/input/titanic/test_data.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Load the Titanic dataset\ntrain_data = pd.read_csv('/kaggle/input/titanic/train_data.csv')\ntest_data = pd.read_csv('/kaggle/input/titanic/test_data.csv')\n\n# Select the specified columns\nfeatures = ['Sex', 'Age', 'Fare', 'Pclass_1', 'Pclass_2', 'Pclass_3', 'Family_size']\n\n# Prepare training data\nX_train = train_data[features]\ny_train = train_data['Survived']\n\n# Prepare testing data (assuming same columns as training data)\nX_test = test_data[features]\n\n# Scale numerical features (assuming 'Age' and 'Fare')\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train[['Age', 'Fare']])\nX_test_scaled = scaler.transform(X_test[['Age', 'Fare']])  # Use the same scaler\n\n# Combine scaled and non-scaled features\nX_train_scaled = pd.concat([pd.DataFrame(X_train_scaled, columns=['Age', 'Fare']), X_train.drop(['Age', 'Fare'], axis=1)], axis=1)\nX_test_scaled = pd.concat([pd.DataFrame(X_test_scaled, columns=['Age', 'Fare']), X_test.drop(['Age', 'Fare'], axis=1)], axis=1)\n\n# Choose a model\nmodel = RandomForestClassifier(random_state=42,n_estimators=200)\n\n# Train the model\nmodel.fit(X_train_scaled, y_train)\n\n# Make predictions on the test data\ny_pred = model.predict(X_test_scaled)\n\n# Save predictions to a CSV file (optional)\npredictions_df = pd.DataFrame({'PassengerId': test_data['PassengerId'], 'Survived': y_pred})\npredictions_df.to_csv('predictions.csv', index=False)\npredictions_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}